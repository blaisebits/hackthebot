import pickle
from typing import List, Dict

from langchain_core.messages import AIMessage
from langchain_core.prompt_values import PromptValue
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import Runnable
from langchain_core.runnables.utils import Output
from langgraph.constants import START
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolNode
from langgraph.types import Command

from utils.Configuration import Configuration
from utils.ContextHelpers import build_exploit_task_context, get_new_working_memory
from utils.HostUpdate import get_stub_host
from utils.LLMHelpers import llm_invoke_retry
from utils.OutputFormatters import TaskAnswer, ExploitSuggestions, ExploitStep, ExploitStepStatus, SpecialAgentCaller, \
    ExploitRceCheck
from utils.Prompts import get_exploit_suggestion_prompt_template, get_exploit_planner_prompt_template, \
    get_exploit_step_prompt_template, get_exploit_step_status_template, get_exploit_payload_crafter_template, \
    get_exploit_step_rce_check_prompt
from utils.SpecialAgents import SpecialAgents
from utils.States import StingerState, Host, ExploitTask, Task
from utils.Tasking import get_new_task, expand_exploit_suggestion, create_exploit_step, get_current_exploit_task, \
    format_tool_output
from utils.Tooling import RoboPagesTools

MAX_STEP_RETRIES:int = 5

rb = RoboPagesTools
rb_tools = rb.get_tools()
rb_iae = rb.filter_tools('initial_access_exploit')
sp = SpecialAgents

llm = Configuration["llm"]

payload_crafter_tool_node = ToolNode(rb_iae)
exploit_step_tool_node = ToolNode(rb_tools)

# Checks for a blank state table and loads from disk
# If non-blank state table, save state stable to disk as a pickle
def load_pickle(state: StingerState):
    if "current_task" in state:
        if state["current_task"] > 0:
            # assume task work as be done
            # Pickle state table to disk
            with open('data.pickle', 'wb') as file:
                pickle.dump(state, file)
                return state

    # assume no work has been done or blank state table
    # Load pickle from disk
    with open('data.pickle', 'rb') as file:
        state = pickle.load(file)
    return state

def exploit_agent(state: StingerState):
    task_str:str|None = None
    agent_messages = []
    context = []
    target:Host = ""

    # Tasking workflow:
    #  Checking if working -> proceed to tool calling again
    #  Check if validated -> check for next task
    #  Check if new -> do preflightcheck and tool calls.
    if not state["tasks"][state["current_task"]]["agent"] == "Exploit":  # Not assigned to Exploit
        state["current_task"] = get_new_task("Exploit", state["tasks"])

    if state["tasks"][state["current_task"]]["agent"] == "Exploit":  # Task assigned to Exploit
        if state["tasks"][state["current_task"]]["status"] == "working":  # Task is working
            task_str = state["tasks"][state["current_task"]]["task"]
            # target_ip = state["tasks"][state["current_task"]]["target_ip"]
            # context.append(state["hosts"][target_ip])
            agent_messages.append(AIMessage(f"ExploitAgent: Reworking task {state["current_task"]}: \"{task_str}\"."))

        elif (state["tasks"][state["current_task"]]["status"] == "validated"
              or state["tasks"][state["current_task"]]["status"] == "new"):  # task is validated/new

            if state["tasks"][state["current_task"]]["status"] == "validated":
                state["current_task"] = get_new_task("Exploit", state["tasks"])
                if state["current_task"] == -1:  # No more tasks for this agent
                    return {
                        "messages": [AIMessage("ExploitAgent: No Tasks were marked for execution. Passing to Stinger.")]}

            task_str = state["tasks"][state["current_task"]]["task"]
            # target_ip = state["tasks"][state["current_task"]]["target_ip"]
            state["tasks"][state["current_task"]]["status"] = "working"
            agent_messages.append(AIMessage(f"ExploitAgent: Starting new task {state["current_task"]}: \"{task_str}\"."))

            if not state["tasks"][state["current_task"]]["preflightcheck"]:  # No PFC yet
                if state["tasks"][state["current_task"]]["target_ip"] in state[
                    "hosts"].keys():  # Target IP has entry in host table
                    agent_messages.append(AIMessage(
                        f"ExploitAgent: Sending task {state["current_task"]}: \"{task_str}\" to validator for pre-flight check."))
                    return {
                        "messages": agent_messages,
                        "current_task": state["current_task"]
                    }
                else:
                    # Add blank entry to host table
                    target_host = get_stub_host(state["tasks"][state["current_task"]]["target_ip"])

                    state["hosts"][target_host["ip_address"]] = target_host
                    state["tasks"][state["current_task"]]["preflightcheck"] = True
                    task_str = state["tasks"][state["current_task"]]["task"]
            # target = state["hosts"][state["tasks"][state["current_task"]]["target_ip"]]
            # context.append(state["tasks"][state["current_task"]]["output"]) #any previous failed exploit attempts

        else:  # No tasks available, routing back to Stinger
            return {"messages": [AIMessage("ExploitAgent: No Tasks were marked for execution. Passing to Stinger.")]}

    ## Setting up LLM Call
    if task_str is not None:
        # helper variables
        task_id = state["current_task"]
        target_ip = state["tasks"][ task_id ]["target_ip"]

        #prompt variables
        task_str = state["tasks"][ task_id ]["task"]
        target = state["hosts"][ target_ip ]
        context = state["tasks"][ task_id ]["output"]

        exploit_suggestion_prompt_template = get_exploit_suggestion_prompt_template()
        exploit_suggestion_prompt = exploit_suggestion_prompt_template.invoke(
            {
                "task": task_str,
                "target": target,
                "context": context
            }
        )
        llm_with_tools = llm.bind_tools([ExploitSuggestions])
        response = llm_invoke_retry(llm_with_tools, exploit_suggestion_prompt)
        tasks = response.tool_calls[0]["args"]["tasks"]

        # Create ExploitTask, nest in output for parent Task
        for task in tasks:
            exploit_task = expand_exploit_suggestion(target_ip, task)
            state["tasks"][ state["current_task"] ]["output"].append(exploit_task)
        agent_messages.append(response)
        return {
            "messages": agent_messages,
            "tasks": state["tasks"],
            "current_task": state["current_task"],
            "hosts": state["hosts"]
        }
    else:
        # return no tasks response
        return {"messages": [AIMessage("ExploitAgent: No Tasks were marked for execution. Passing to Stinger.")]}


def validator(state: StingerState):
    current_task_target_ip = state["tasks"][ state["current_task"] ]["target_ip"]
    state["tasks"][state["current_task"]]["preflightcheck"] = True

    if state["hosts"][current_task_target_ip]["initial_access_exploit"] == "":
        # No exploit for the host
        return {
            "messages": [AIMessage("ExploitValidator: No Initial Access Payload available. Passing to ExploitAgent.")]
        }
    else:
        # Exploit present for host
        state["tasks"][state["current_task"]]["status"] = "validated"
        question = state["tasks"][state["current_task"]]["task"]

        # TODO Update the logic for these values
        # Need to fix to actually run a test of the IAP to get command output.
        answer = "Successfully tested Initial Access Payload from Host."
        # Update to capture the output from the IAP test.
        reason = "The IAP for the host is present"

        response = TaskAnswer(
            question=question,
            answer=answer,
            reason=reason
        )
        state["tasks"][state["current_task"]]["verdict"] = response

        target_ip = state["tasks"][state["current_task"]]["target_ip"]
        state["hosts"][target_ip]["verdicts"].append(response)

        return {
            "messages": [AIMessage(f"ReconValidator: Task {state["current_task"]} validated.\n"
                                   f"Question: {response.question}\n"
                                   f"Answer: {response.answer}\n")],
            "tasks": state["tasks"]
        }


def handoff(state: StingerState):
    """Hand off back to stinger"""
    return Command(
        goto="StingerAgent",
        update=state,
        graph=Command.PARENT
    )

def exploit_router(state: StingerState):
    last_message = state["messages"][-1]
    current_task = state["tasks"][state["current_task"]]
    preflightcheck = current_task["preflightcheck"]

    if last_message.tool_calls:
        if last_message.tool_calls[0]["name"] == "ExploitSuggestions":
            return "ExploitStepPlanner"
        else:
            return "ExploitToolNode"
    if not preflightcheck: return "ExploitValidator"

    return "ExploitHandoff"

def exploit_step_planner(state: StingerState):
    """
    Task the current exploit task and plan the ExploitSteps needed
    """
    # Extract helper variables
    current_task = state["current_task"]
    target_ip = state["tasks"][ current_task ]["target_ip"]
    target = state["hosts"][target_ip]

    # Extract the current working ExploitTask from Task.output
    exploit_task = None
    exploit_task_index = None
    for index, element in enumerate(state["tasks"][current_task]["output"]):
        if element["status"] == "new":
            exploit_task = element
            exploit_task_index = index
            break

    # Bail out back to Exploit Suggestion
    # if exploit_task == None

    # Call LLM to supply ExploitSteps to complete the task
    exploit_planner_prompt_template = get_exploit_planner_prompt_template()
    exploit_planner_prompt = exploit_planner_prompt_template.invoke(
        {
            "exploit_task": exploit_task["task"],
            "target": target,
            "context": ""
        }
    )

    llm_with_tools = llm.bind_tools([ExploitStep])
    response = llm_invoke_retry(llm_with_tools, exploit_planner_prompt)

    #Update state table
    steps = response.tool_calls[0]["args"]["steps"]
    exploit_steps: [ExploitStep] = list(map(lambda x: create_exploit_step(x), steps))
    exploit_steps.append(create_exploit_step("Create initial access exploit for the target"))

    state["tasks"][ current_task ]["output"][exploit_task_index]["steps"] = exploit_steps
    state["tasks"][ current_task ]["output"][exploit_task_index]["status"] = "working"

    return {
        "tasks": state["tasks"]
    }

def exploit_step_processor(state: StingerState):
    """
    Finds the ExploitTask current_step and send the step with data
    to the LLM to find a tool.
    """
    exploit_task_index:int = get_current_exploit_task(state)

    exploit_task:ExploitTask = state["tasks"][ state["current_task"] ]["output"][ exploit_task_index ]
    exploit_steps:List[ExploitStep] = exploit_task["steps"]
    current_step:int = exploit_task["current_step"]
    context = build_exploit_task_context(state, exploit_task_index)
    on_last_step: bool = len(exploit_steps) == current_step

    # Check for early RCE after first step is completed
    # TODO should we merge this to the exploit revizor???
    # TODO Yes, move to Revizor
    # TODO Enforce stricter check for RCE
    if current_step > 0 and not on_last_step:
        exploit_rce_check_prompt_template = get_exploit_step_rce_check_prompt()
        exploit_rce_check_prompt = exploit_rce_check_prompt_template.invoke({
            "context": context
        })

        llm_with_tools = llm.bind_tools([ExploitRceCheck])
        response = llm_invoke_retry(llm_with_tools, exploit_rce_check_prompt)

        # TODO
        # If RCE happened -> set remaining steps to skipped, except the last one for IAE
        # Update
        rce_check:bool = response.tool_calls[0]["args"]["rce"]

        if rce_check:
            step_length:int = len(exploit_steps)

            for i in range(current_step,step_length-2):
                state["tasks"][ state["current_task"] ]["output"][ exploit_task_index ]["steps"][i]["status"] = "skipped"

            state["tasks"][state["current_task"]]["output"][exploit_task_index]["current_step"] = step_length-1
            current_step: int = step_length-1



    # Might need else block for this
    exploit_step:ExploitStep = exploit_steps[current_step]
    step_task = exploit_step["step_task"]

    exploit_step_prompt_template = get_exploit_step_prompt_template()
    exploit_step_prompt = exploit_step_prompt_template.invoke(
        {
            "agents": sp.agent_prompt_data(),
            "step": step_task,
            "context": context
        }
    )

    llm_with_tools = llm.bind_tools(rb_tools+[SpecialAgentCaller])
    response = llm_invoke_retry(llm_with_tools, exploit_step_prompt)

    if response.tool_calls[0]["name"] == 'SpecialAgentCaller':
        state["tasks"][ state["current_task"] ]["output"][exploit_task_index]["steps"][current_step]["tool"].append(f"SpecialAgentCaller:{response.tool_calls[0]["args"]["name"]}")
        state["tasks"][ state["current_task"] ]["output"][exploit_task_index]["steps"][current_step]["status"] = "working"
    else:
        state["tasks"][ state["current_task"] ]["output"][exploit_task_index]["steps"][current_step]["tool"].append(response.tool_calls[0]["name"])
        state["tasks"][ state["current_task"] ]["output"][exploit_task_index]["steps"][current_step]["status"] = "working"

    return {
        "messages": response,
        "tasks": state["tasks"]
    }

def exploit_step_tool_router(state:StingerState):
    # Check the last message tool call for the name of the tool
    if state["messages"][-1].tool_calls[0]["name"] == 'SpecialAgentCaller':
        return "ExploitSpecialAgentNode"
    else:
        return "ExploitStepToolNode"

async def exploit_step_special_agent_node(state: StingerState):
    agent_to_call = state["messages"][-1].tool_calls[0]["args"]["name"]
    response = await sp.agents[agent_to_call].graph.ainvoke(state)
    # print(response)
    return response

def exploit_step_update(state: StingerState):
    ai_messages:List[AIMessage] = []
    current_task:int = state["current_task"]
    task:Task = state["tasks"][ current_task ]
    exploit_task_index:int = get_current_exploit_task(state)

    exploit_task:ExploitTask = task["output"][ exploit_task_index ]
    current_step:int = exploit_task["current_step"]

    last_message = state["messages"][-1]
    if last_message.type == 'tool':
        ai_messages.append(AIMessage("ExploitStepUpdate: Appending Tool call output"))
        tool_output = last_message.content
        state["tasks"][state["current_task"]]["output"][exploit_task_index]["steps"][current_step]["output"].append(tool_output)
        return {
            "messages": ai_messages,
            "tasks":state["tasks"]
        }
    else:
        return {
            "messages": AIMessage("ExploitStepUpdate: No Tool Call output found.")
        }

def exploit_step_revizor(state: StingerState):
    """
    Check if the exploitstep executed correctly
    If step tool array length is >= MAX_RETRIES then mark as failed and bail
    If validated, setup to move on to next step
    if failed, update step with revision
    """
    # TODO Fix issues where revizor never calls LLM to update task
    ai_messages:List[AIMessage] = []
    current_task:int = state["current_task"]
    task:Task = state["tasks"][current_task]
    exploit_task_index:int = get_current_exploit_task(state)

    exploit_task:ExploitTask = task["output"][exploit_task_index]
    current_step:int = exploit_task["current_step"]
    # noinspection PyTypeChecker
    exploit_step:ExploitStep = exploit_task["steps"][ current_step ]

    # Check for step failure
    if len(exploit_step["tool"]) >= MAX_STEP_RETRIES:
        state["tasks"][current_task]["output"][exploit_task_index]["steps"][current_step]["status"] = "failed"
        state["tasks"][current_task]["output"][exploit_task_index]["status"] = "failed"
        ai_messages.append(AIMessage(f"ExploitStepRevizor: Exploit Task {exploit_task_index}, step {current_step}, has failed."
                                     f" Bailing out on ExploitTask."))
        return {
            "messages": ai_messages,
            "tasks": state["tasks"]
        }

    # Check the step status, call language model for verdict
    ai_messages.append(AIMessage(f"ExploitStepRevizor: Checking status of Exploit Task {exploit_task_index}, step {current_step}."))

    step_task:str = exploit_step["step_task"]
    task_output:dict = format_tool_output(exploit_step["tool"], exploit_step["output"])

    exploit_step_status_template:ChatPromptTemplate = get_exploit_step_status_template()
    exploit_step_status_prompt:PromptValue = exploit_step_status_template.invoke(
        {
            "task": step_task,
            "output": task_output
        }
    )

    llm_with_tools:Runnable = llm.bind_tools([ExploitStepStatus])
    response:Output =  llm_invoke_retry(llm_with_tools,exploit_step_status_prompt)

    ai_messages.append(response)
    status = response.tool_calls[0]["args"]["status"]
    revision = response.tool_calls[0]["args"]["revision"]
    insert_step = response.tool_calls[0]["args"]["insert_step"]

    if status == "validated":
        # Update the step and increment current step for the exploit task
        state["tasks"][ current_task ]["output"][ exploit_task_index ]["steps"][ current_step ]["status"] = "validated"
        state["tasks"][current_task]["output"][exploit_task_index]["current_step"] = current_step+1 if exploit_task["steps"]!=current_step else current_step
        return {
            "messages": ai_messages,
            "tasks": state["tasks"]
        }
    elif status == "failed":
        # error correction LLM call
        # Leave status as working
        ai_messages.append(AIMessage(f"ExploitStepRevizor: Revising Exploit Task {exploit_task_index}, step {current_step}: {revision}"))

        # Check for insert_step to create new step and insert before current step
        if insert_step:
            state["tasks"][current_task]["output"][exploit_task_index]["steps"].insert(current_step, create_exploit_step(revision))
        else:
            state["tasks"][current_task]["output"][exploit_task_index]["steps"][current_step]["step_task"] = revision

        return {
            "messages": ai_messages,
            "tasks": state["tasks"]
        }
    else:
        # bail out because LLM call sucks/failed

        return {}

def exploit_step_router(state:StingerState):
    exploit_task_index: int = get_current_exploit_task(state)
    exploit_task: ExploitTask = state["tasks"][state["current_task"]]["output"][exploit_task_index]
    last_step: ExploitStep = exploit_task["steps"][-1]

    current_step_index: int = exploit_task["current_step"]
    exploit_step: ExploitStep = exploit_task["steps"][current_step_index]

    # If current_step is "failed" assume ExploitTask failed -> ExploitAgent
    # else if last_step is validated -> ExploitPayloadCrafter
    # else -> ExploitSteProcessor
    if exploit_step["status"] == 'failed':
        return "ExploitAgent"
    elif last_step["status"] == 'validated':
        return "ExploitPayloadCrafter"
    else:
        return "ExploitStepProcessor"


# TODO: REMOVE THESE FUNCTIONS
def exploit_payload_crafter(state:StingerState):
    # examine the context of all the exploit steps, LLM verify if looks legit
    # Test get IAE and verify it works

    exploit_task_index: int = get_current_exploit_task(state)
    parent_task: Task = state["tasks"][state["current_task"]]

    task: str = parent_task["task"]

    exploit_payload_crafter_template: ChatPromptTemplate = get_exploit_payload_crafter_template()

    # Working memory loop
    if state["working_memory"]["caller"] == 'exploit_payload_crafter':
        state["working_memory"]["data"]["attempts"]
        # Continue crafting loop
        state["working_memory"]["data"]["attempts"]+=1

        # Use message history which include previous context
        # Check if the IAE works -> then add to target host table
        # else -> make another pass

    else:
        # start new crafting loop
        state["working_memory"] = get_new_working_memory() # init new working memory
        state["working_memory"]["data"]["attempts"] = 0

        # Use full exploit context at first
        context: str = build_exploit_task_context(state, exploit_task_index)
        exploit_payload_crafter_prompt: PromptValue = exploit_payload_crafter_template.invoke(
            {
                "task": task,
                "context": context
            }
        )
        llm_with_tools: Runnable = llm.bind_tools(rb_iae)
        response: Output = llm_invoke_retry(llm_with_tools, exploit_payload_crafter_prompt)

        # Track IAE in state:working_memory
        state["working_memory"]= {
            "caller": "exploit_payload_crafter",
            "messages": response,
            "data": {}
        }

    return {
        "messages": state["working_memory"]["messages"],
        "working_memory": state["working_memory"]
    }

def exploit_payload_crafter_router(state:StingerState):
    #Check last message for tool cools
    if state["messages"][-1].tool_calls:
        return "ExploitPayloadCrafterToolNode"
    else:
        return "ExploitAgent"

exploit_workflow = StateGraph(StingerState)

exploit_workflow.add_edge(START, "LoadPickle")
exploit_workflow.add_node("LoadPickle", load_pickle)

exploit_workflow.add_edge("LoadPickle", "ExploitAgent")
exploit_workflow.add_node("ExploitAgent", exploit_agent)

exploit_workflow.add_conditional_edges("ExploitAgent", exploit_router, ["ExploitHandoff", "ExploitValidator", "ExploitStepPlanner"])
#TODO REMOVE THIS
#commenting out for now, might put back in, if don't delete tool node
#exploit_workflow.add_conditional_edges("ExploitAgent", exploit_router, ["ExploitToolNode", "ExploitHandoff", "ExploitValidator", "ExploitStepPlanner"])
#exploit_workflow.add_node("ExploitToolNode", exploit_tool_node)
exploit_workflow.add_node("ExploitHandoff", handoff)
exploit_workflow.add_node("ExploitValidator", validator)
exploit_workflow.add_edge("ExploitValidator", "ExploitAgent")

###################################
# Nodes for executing exploit steps
###################################
exploit_workflow.add_node("ExploitStepPlanner", exploit_step_planner)

exploit_workflow.add_edge("ExploitStepPlanner", "ExploitStepProcessor")
exploit_workflow.add_node("ExploitStepProcessor", exploit_step_processor)

exploit_workflow.add_conditional_edges("ExploitStepProcessor", exploit_step_tool_router, ["ExploitStepToolNode", "ExploitSpecialAgentNode"])
exploit_workflow.add_node("ExploitStepToolNode", exploit_step_tool_node)
exploit_workflow.add_node("ExploitSpecialAgentNode", exploit_step_special_agent_node)

exploit_workflow.add_edge("ExploitStepToolNode", "ExploitStepUpdate")
exploit_workflow.add_edge("ExploitSpecialAgentNode", "ExploitStepUpdate")
exploit_workflow.add_node("ExploitStepUpdate", exploit_step_update)

exploit_workflow.add_edge("ExploitStepUpdate","ExploitStepRevizor")
exploit_workflow.add_node("ExploitStepRevizor", exploit_step_revizor)

exploit_workflow.add_conditional_edges("ExploitStepRevizor", exploit_step_router, ["ExploitStepProcessor","ExploitAgent"])
# exploit_workflow.add_conditional_edges("ExploitStepRevizor", exploit_step_router, ["ExploitStepProcessor","ExploitPayloadCrafter"])
# exploit_workflow.add_node("ExploitPayloadCrafter", exploit_payload_crafter)
# exploit_workflow.add_conditional_edges("ExploitPayloadCrafter",exploit_payload_crafter_router, ["ExploitPayloadCrafterToolNode","ExploitAgent"])
#
# exploit_workflow.add_edge("ExploitPayloadCrafterToolNode","ExploitPayloadCrafter")
# exploit_workflow.add_node("ExploitPayloadCrafterToolNode",exploit_step_tool_node)


exploit_graph = exploit_workflow.compile()

if __name__ == "__main__":
    # print(os.getcwd())
    exploit_graph.invoke({})